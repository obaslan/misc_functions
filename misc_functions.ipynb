{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Misc. Functions\n",
    "running:  \n",
    "F = open(\"Library_address.txt\",'r') \n",
    "Library_address = F.read()  \n",
    "%run $Library_address/misc_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "from pandas import rolling_median, rolling_mean\n",
    "import math\n",
    "exp=math.exp\n",
    "pi=math.pi\n",
    "inf=math.inf\n",
    "\n",
    "# Default folder,file properties\n",
    "DF = open(\"Directory_address.txt\",'r') \n",
    "Directory_address = DF.read()\n",
    "\n",
    "folder_address = r\"C:\\Users\\Aslan\\Desktop\\Pyhton_Coding\\Inputs\"\n",
    "folder_address = Directory_address + \"\\Inputs\"\n",
    "\n",
    "output_folder_address = r\"C:\\Users\\Aslan\\Desktop\\Pyhton_Coding\\Outputs\"\n",
    "output_folder_address = Directory_address + \"\\Outputs\"\n",
    "def_file_name= \"data\"\n",
    "file_labels = \"\"\n",
    "data_type= \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Animated plots\n",
    "#http://tiao.io/posts/notebooks/embedding-matplotlib-animations-in-jupyter-notebooks/\n",
    "\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "def plot_animation(data):\n",
    "    fig, ax = plt.subplots(figsize=(5, 3))\n",
    "    #ax.set( xlim=(1.4, 1.9), ylim=(-40, data.max() ) )\n",
    "    ax.set(ylim=(-40, data.max() ) )\n",
    "\n",
    "    line = ax.plot(data[:,0], data[:,1], color='k', lw=2)[0]\n",
    "\n",
    "    anim = FuncAnimation(\n",
    "        fig, animate, interval=1000, frames = range(1, len(data[0,:])), fargs= (data.T,line) )\n",
    "\n",
    "    return HTML(anim.to_html5_video()) , HTML(anim.to_jshtml())\n",
    "\n",
    "def animate(i, *fargs):\n",
    "    y = fargs[0]\n",
    "    line = fargs[1]\n",
    "    line.set_ydata(y[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def despike(data, window = 20, n_deviation = 0.35):\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    data_median_pd = df.copy()\n",
    "    data_diff_pd = df.copy()\n",
    "    outlier_idx =  df.copy()\n",
    "    data_despiked = df.copy()\n",
    "    row,column = data.shape\n",
    "    \n",
    "    for n in range(1,column):\n",
    "        data_median_pd[n] = rolling_median(df[n], window=window, center=True).fillna(method='bfill').fillna(method='ffill')\n",
    "        data_diff_pd[n] = np.abs(df[n] - data_median_pd[n]) # deviation from the rolling median\n",
    "\n",
    "        outlier_idx[n] = data_diff_pd[n] > n_deviation*df[n].std() # spike: if the deviation is much more than the global standard deviation\n",
    "\n",
    "        data_despiked[n][outlier_idx[n]] = data_median_pd[n][outlier_idx[n]] # replaced the spikes with the rolling median values\n",
    "\n",
    "        if outlier_idx[n].any(): # plot if any spike is detected\n",
    "            # the following plots most of the relavent calculations\n",
    "            #smart_plot([  df[0], df[0][outlier_idx[n] ], df[0], df[0], df[0],df[0] ], [ df[n], df[n][outlier_idx[n]], data_median_pd[n], data_diff_pd[n], df_mad, data_despiked[n] ], x_label='Energy (eV)', y_label='PL',\n",
    "            #          label = ['data', 'spikes', 'median', 'data-median', 'deviation', 'despiked' ],lines=['-','x','--', '-','-','-'], ms=[1,15,1,1,1,1], annotate = 3, figsize=(16,10))\n",
    "\n",
    "\n",
    "            smart_plot([ df[0], df[0]  ], [ df[n],  data_despiked[n] ], legend_title='Removing Spikes',label = [data_labels[n], 'After removal'], x_label='Energy (eV)', y_label='PL', lines=['-','-'], ms=[1,15], annotate = 0)\n",
    "\n",
    "    plt.show()\n",
    "    return data_despiked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_eff(data, eff, data_labels=[], eff_labels=[], file_name='', material='',\n",
    "                x_normalize = 1.60, # x value at which the inverse efficiency is 1\n",
    "                x_lower = 1.4, x_upper = 1.9\n",
    "    ):\n",
    "    \n",
    "    \n",
    "    x_normalize = {'MoSe2': 1.50 ,'MoS2': 1.80, 'WSe2':1.60, 'WS2': 1.95 }.get(material, x_normalize)\n",
    "    \n",
    "    # auto-assign the limits if the material is specified\n",
    "    x_lower, x_upper = {'MoSe2': [1.35, 1.8] , 'WSe2': [1.3, 1.9],'WS2': [1.8, 2.2] }.get(material, [x_lower, x_upper])\n",
    "    \n",
    "    ## interpolate the efficiency range to the range of the data imported\n",
    "    # create a new np_array of 2 columns for interpolated efficiency\n",
    "    eff_interp=np.zeros(shape=(len(data[:,0]),2))\n",
    "\n",
    "    # x values to interpolate for\n",
    "    eff_interp[:,0] = data[:,0]\n",
    "\n",
    "    eff_interp[:,1]=interpolate.interp1d(eff[:,0], eff[:,1])(eff_interp[:,0])\n",
    "    smart_plot([eff_interp[:,0],eff[:,0]],[eff_interp[:,1],eff[:,1]], y_label='Collection Efficiency', label=['Interpolated ','Whole Range'], lw=[4,2],figsize=(10,3), legend_title=eff_labels[1])   \n",
    "    \n",
    "    \n",
    "    # assign the inverse collection efficiency to a separate list    \n",
    "    idx = (np.abs(eff_interp[:,0] - x_normalize)).argmin() # the index where x_normalize is\n",
    "\n",
    "    normal_inverse_eff=eff_interp[idx,1]/eff_interp[:,1] \n",
    "    smart_plot([eff_interp[:,0]],[normal_inverse_eff], x_label='Energy (eV)', y_label='Normalized Inverse \\n Collection Efficiency', figsize=(9,4))\n",
    "    \n",
    "    # Correct the data for the collection efficiency\n",
    "    row,column = data.shape\n",
    "\n",
    "    data_eff_corrected = np.zeros_like(data)\n",
    "\n",
    "    m=1 # Column to plot before and after interpolation\n",
    "    data_eff_corrected[:,0] = data[:,0]\n",
    "    for n in range(1,column):\n",
    "        data_eff_corrected[:,n]=np.multiply(normal_inverse_eff, data[:,n])\n",
    "    #custom_limit_x=1, x_min=1.4, x_max=1.9,\n",
    "    smart_plot([data[:,0],data_eff_corrected[:,0]], [data[:,m],data_eff_corrected[:,m]],label=[data_labels[m],\"Efficiency Corrected\"], custom_limit_x=1, x_min=x_lower, x_max=x_upper,  figsize=(9,4))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    if file_name != '':\n",
    "        export_np(data_eff_corrected, file_name= 'data_eff_corrected_' + file_name ) # do not export the smoothed data\n",
    "    return data_eff_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subtract_ref (data, data_labels=[], ref=[['']], ref_labels=[], file_name='',\n",
    "                  x_lower = 1.4, x_upper = 1.9, material=''):\n",
    "    \n",
    "    # auto-assign the limits if the material is specified\n",
    "    x_lower, x_upper = {'MoSe2': [1.35, 1.8] , 'WSe2': [1.3, 1.9],'WS2': [1.8, 2.2] }.get(material, [x_lower, x_upper])\n",
    "\n",
    "    row,column = data.shape\n",
    "    data_ref_subtracted = np.zeros_like(data)\n",
    "    data_ref_subtracted[:,0]= data[:,0]\n",
    "    \n",
    "    if ref[0][0]: # if a reference is provided\n",
    "        # interpolate the reference range to the range of the data imported\n",
    "        # create a new np_array of 2 columns for interpolated reference\n",
    "        ref_interp = np.zeros(shape=(len(data[:,0]),2))\n",
    "\n",
    "        # x values to interpolate for\n",
    "        ref_interp[:,0] = data[:,0]\n",
    "        ref_interp[:,1] = interpolate.interp1d(ref[:,0], ref[:,1])(ref_interp[:,0])\n",
    "\n",
    "        smart_plot([ref_interp[:,0],ref[:,0]],[ref_interp[:,1],ref[:,1]], label=['interpolated '+ref_labels[1],'Reference'], lw=[4,2],figsize=(12,4))\n",
    "\n",
    "        # Correct the data by subtracting the reference signal\n",
    "        for n in range(1,column):\n",
    "            data_ref_subtracted[:,n]=np.subtract(data[:,n], ref_interp[:,1])\n",
    "            smart_plot([data[:,0],data_ref_subtracted[:,0]], [data[:,n],data_ref_subtracted[:,n]],label=[data_labels[n],\"Reference Subtracted\"],  custom_limit_x=1, x_min=x_lower, x_max=x_upper,autoscale_view_y=0)\n",
    "\n",
    "    else : # no reference is provided\n",
    "        # Correct the data by subtracting a linear baseline signal (obtained by fitting 2 points (averaged over 10 points each) of data to a line)\n",
    "\n",
    "        m=5 # Column to plot before and after interpolation\n",
    "        if m > column:# not as many columns in the data\n",
    "            m = 1\n",
    "\n",
    "        x_lower_index = find_nearest(data[:,0], x_lower)[0]\n",
    "        x_upper_index = find_nearest(data[:,0], x_upper)[0]\n",
    "\n",
    "        for n in range(1,column):\n",
    "            baseline = scipy.polyfit( [x_lower, x_upper], [ np.average(data[x_lower_index-5:x_lower_index+5,n]) , np.average(data[x_upper_index-5:x_upper_index+5, n]) ], 1 )\n",
    "            data_ref_subtracted[:,n] = data[:,n] - data[:,0]*baseline[0]-baseline[1]\n",
    "            smart_plot([data[:,0]]*3 + [[x_lower-0.1,(x_lower+x_upper)/2, x_upper+0.1]], [ data[:,n], data_ref_subtracted[:,n], data[:,n]-data_ref_subtracted[:,n], [0,0,0] ], label=[data_labels[n],\"After Subtraction\", 'Baseline (%.2fx+%.2f)' %(baseline[0], baseline[1]), 'Zero'],  custom_limit_x=1, x_min=x_lower, x_max=x_upper)\n",
    "    plt.show()\n",
    "    if file_name != '':\n",
    "        export_np(data_ref_subtracted, file_name='data_ref_subtracted_'+ file_name)\n",
    "        \n",
    "    return data_ref_subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smoother(data, data_labels, smooth_window_length = 9, polyorder = 2,\n",
    "             x_lower = 1.4, x_upper = 1.9, material=''):\n",
    "    \n",
    "    row,column = data.shape\n",
    "    data_smooth = np.zeros_like(data)\n",
    "    data_smooth[:,0] = data[:,0]\n",
    "    \n",
    "    # auto-assign the limits if the material is specified\n",
    "    x_lower, x_upper = {'MoSe2': [1.35, 1.8] , 'WSe2': [1.3, 1.9],'WS2': [1.8, 2.2] }.get(material, [x_lower, x_upper])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    n=1\n",
    "    for n in range(1,column):\n",
    "        data_smooth[:,n]=scipy.signal.savgol_filter([data[:,0],data[:,n]], smooth_window_length, polyorder, deriv=0, axis=1)[1]\n",
    "        #smart_plot( [data_smooth[:,0], data_smooth[:,0], [x_min, x_max]], [data[:,n], data_smooth[:,n] , [0,1] ], label=[data_labels[n], 'data_smooth', '0 line'], lw=[4,2,.5], figsize=(9,3),  custom_limit_x=1, x_min=x_min, x_max=x_max)\n",
    "        #, custom_limit_x=1, x_min=x_lower, x_max=x_upper\n",
    "        smart_plot( [data_smooth[:,0], data_smooth[:,0], [x_lower, (x_lower+x_upper)/2, x_upper]], [data[:,n], data_smooth[:,n] , [0,0,0] ], label=[data_labels[n], 'data_smooth', '0 line'], lw=[4,2,.5], figsize=(9,3), custom_limit_x=1, x_min=x_lower, x_max=x_upper)\n",
    "\n",
    "    plt.show()\n",
    "    return data_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO : Plot vertical lines at peak positions\n",
    "def peak_analyzer(data, x_lower=0, x_upper=4, is_print_report = 0, data_labels=[''], file_name='', pressures=[''], diameters=[''],\n",
    "                 material='', \n",
    "                is_map=[0,0,0] # boolean for x,y,z coordinates if mapping\n",
    "                 ):\n",
    "    #if len(x) is not len(y) :\n",
    "       # print('x and y do not have the same length')\n",
    "        #return\n",
    "    # auto-assign the limits if the material is specified\n",
    "    x_lower, x_upper = {'MoSe2': [1.35, 1.8] , 'WSe2': [1.3, 1.9],'WS2': [1.8, 2.2] }.get(material, [x_lower, x_upper])\n",
    "    # typical, good linewidth\n",
    "    typ_linewidth = {'MoSe2': 40 ,'MoS2': 50, 'WSe2': 42, 'WS2': 30 }.get(material, 30)\n",
    "    \n",
    "    header = ['Peak Energy', 'X half-left', 'X half-right', 'Linewidth', 'Asymmetry', 'Max Amplitude', 'Integ. Area']\n",
    "    result = []    \n",
    "    for n in range(1, len(data[1,:])): # for all y columns of the data\n",
    "        \n",
    "        x = data[:,0] # reassign the x each time to have it in numpy format which works in the select_range() method\n",
    "        y = data[:,n]\n",
    "    \n",
    "        x, y = select_range(x, y, x_lower, x_upper)\n",
    "\n",
    "        x = list(x)\n",
    "        y = list(y)\n",
    "\n",
    "        Area=np.trapz(y,x)\n",
    "        ymax=max(y)\n",
    "        ymin=min(y)\n",
    "\n",
    "        N=len(y)\n",
    "        lev50 = ymax/2.0\n",
    "\n",
    "        if y[0] < lev50 :                # find index of center (max or min) of pulse\n",
    "            centerindex= y.index(ymax)\n",
    "            #centerindex, value = max(y, key=lambda y: y[1])\n",
    "            xmax = x[centerindex]\n",
    "            Pol = +1\n",
    "            if is_print_report:\n",
    "                print('Pulse Polarity = Positive')\n",
    "        else :\n",
    "            centerindex= y.index(ymin)\n",
    "            xmin = x[centerindex]\n",
    "            Pol = -1\n",
    "            if is_print_report:\n",
    "                print('Pulse Polarity = Negative')\n",
    "\n",
    "        i = 2\n",
    "        while (np.sign(y[i]-lev50) == np.sign(y[i-1]-lev50)) :\n",
    "            i = i+1\n",
    "            #first crossing is between y(i-1) & y(i)\n",
    "        interp = (lev50-y[i-1]) / (y[i]-y[i-1])\n",
    "        tlead = x[i-1] + interp*(x[i]-x[i-1])\n",
    "\n",
    "        i = centerindex+1                  #start search for next crossing beyond the center\n",
    "        while ((np.sign(y[i]-lev50) == np.sign(y[i-1]-lev50)) and (i <= N-1)):\n",
    "            i = i+1\n",
    "\n",
    "        if i is not N :\n",
    "            if is_print_report:\n",
    "                print('Pulse is Impulse or Rectangular with 2 edges')\n",
    "            interp = (lev50-y[i-1]) / (y[i]-y[i-1])\n",
    "            ttrail = x[i-1] + interp*(x[i]-x[i-1])\n",
    "            width =  ttrail-tlead\n",
    "        else:\n",
    "            Ptype = 2\n",
    "            if is_print_report:\n",
    "                print('Step-Like Pulse, no second edge')\n",
    "            ttrail = 'NaN'\n",
    "            width = 'NaN'\n",
    "\n",
    "        asymmetry =(xmax-ttrail)/(tlead-xmax)\n",
    "        result.append([xmax, ttrail, tlead, abs(width*1000), asymmetry, ymax, abs(Area)]) #label=[data_labels[n], 'Width %.1fmeV' %width*1000, 'Peak %.3f eV' %xmax]\n",
    "        smart_plot( [x, [ttrail, tlead], [ttrail, tlead] ], [ y, [ymax/2,ymax/2], [ymax,ymax] ], label=[data_labels[n], '%.1f meV (Width)' %abs(width*1000), '%.3f eV (Peak)' %xmax] , lw=[4,2,.5], figsize=(9,3) , v_lines=[xmax], autoscale_view_y=0 )#, custom_limit_x=1, x_min=x_lower, x_max=x_upper\n",
    "                  \n",
    "        plt.show()\n",
    "    units = ['eV', 'eV', 'eV', 'meV', '', '', '']\n",
    "    index = pd.MultiIndex.from_arrays([header, units])\n",
    "    fit_report = pd.DataFrame(result, index=data_labels[1:], columns=index)\n",
    "\n",
    "\n",
    "    if is_map[0]: #x coordinate\n",
    "        fit_report.insert(0, 'x', [item[0] for item in coordinates])\n",
    "    if is_map[1]: #y coordinate\n",
    "        fit_report.insert(1, 'y', [item[1] for item in coordinates])\n",
    "    if is_map[2]: #z coordinate\n",
    "        fit_report.insert(2, 'z', [item[2] for item in coordinates])\n",
    "        \n",
    "    #fit_report.columns.set_levels( ['1','2'] + units, level=1,inplace=True)\n",
    "        \n",
    "    # Add a column for futher calculations\n",
    "    #if not all(pressure == '' for pressure in pressures):\n",
    "    #    psi = 6894.744825 # 1 psi in N/m^2\n",
    "    #    micron = 10**-6 # 1 micrometer in meters\n",
    "    #    PR_2_3rd = [(pressure*psi* diameter*micron/2)**(2/3) for (pressure,diameter) in zip(pressures,diameters)]\n",
    "    #    fit_report.insert(0, '(Pressure x Radius)\\+(2/3)', PR_2_3rd)\n",
    "    \n",
    "    if file_name != '':\n",
    "        #export_np(header, file_name='analysis_'+ file_name, header= '\\t'.join(header))\n",
    "        export_pd(fit_report, file_name='analysis_'+ file_name, index=True, header=True)\n",
    "        \n",
    "\n",
    "    for j in range(len(result[0])):\n",
    "        fit_report[header[j]] = [item[j] for item in result]\n",
    "    \n",
    "    #fit_report.columns=fit_report.columns.str.replace('#','') \n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(fit_report['Peak Energy','eV'], fit_report['Linewidth'], label='A exciton', marker='o', markersize=12, color=\"red\")\n",
    "    plt.plot( [min(fit_report['Peak Energy','eV']), max(fit_report['Peak Energy','eV'])  ], [typ_linewidth]*2, ls='--', label= material+' typical', color=\"blue\")\n",
    "    plt.xlabel('Peak Energy (eV)')\n",
    "    plt.ylabel('Linewidth (meV)')\n",
    "    plt.legend()\n",
    "    fig.set_size_inches(w=8,h=6)\n",
    "    plt.show()\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.3f}'.format # display 3 decimals          \n",
    "    return fit_report #,['%.3f' % i for i in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the zero columns of data and its labels, export the nonzero data and return it and the nonzero labels\n",
    "def remove_zero_columns(data, data_labels=[], file_name=''):\n",
    "    row,column=data.shape\n",
    "    zero_columns = []\n",
    "\n",
    "    for n in range(column):\n",
    "        if not any(data[0:2,n]) : # if 1st 3 rows are 0\n",
    "            zero_columns.append(n)   \n",
    "    \n",
    "    n_zero_columns = len(zero_columns) # total number of zero columns\n",
    "            \n",
    "    print(\"%d nonzero + %d zero = %d columns\" %(column-n_zero_columns, n_zero_columns, column))\n",
    "    \n",
    "    data_nonzero = np.delete(data, zero_columns, 1)\n",
    "    if file_name != '':\n",
    "        export_np(data_nonzero, file_name='data_nonzero_'+file_name)\n",
    "        \n",
    "    if data_labels: \n",
    "        data_nonzero_labels = list(np.delete(data_labels, zero_columns)) \n",
    "        return data_nonzero, data_nonzero_labels,n_zero_columns\n",
    "    else:\n",
    "        return data_nonzero,n_zero_columns    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evenly_space(x, y, step_size=0.001, # step size of the new x values to be interpolated\n",
    "                 is_plot = 0 #\n",
    "               ): \n",
    "    \n",
    "    interp=[] # interpolator\n",
    "    column = len(y[0])\n",
    "    \n",
    "    label=['interpolated','data']; lw=[4,2]\n",
    "    kwargs = {'title' : '', 'legend_title' : legend_title, 'label': label, 'legend_fs' : legend_fs, 'lines' : lines, 'lw' : lw, 'ms' : ms, 'x_label' : x_label, 'y_label' : '1', 'figsize' : (12,4)\n",
    "         ,'is_x_numeric' : 1}\n",
    "    \n",
    "    # x values to interpolate for\n",
    "    x_interp = np.arange(min(x), max(x), step_size)\n",
    "\n",
    "    y_interp=np.zeros(shape=(len(x_interp),column))\n",
    "\n",
    "    for n in range(0, len(y[0,:])): # for all y columns of the data\n",
    "        interp.append(interpolate.interp1d(x, y[:,n]))\n",
    "        \n",
    "        kwargs['legend_title'] = data_labels[n] ; \n",
    "        y_interp[:,n]=interp[n](x_interp)  \n",
    "        if is_plot:\n",
    "            smart_plot([x_interp, x],[y_interp[:,n], y[:,n]],  **kwargs)\n",
    "    if is_plot:\n",
    "        plt.show()\n",
    "    return x_interp, y_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth_deriv(x, y, deriv=1, # derivative order\n",
    "                 polyorder=1, # polynomial order for smoothing\n",
    "                 derive_length=3, # smoothing window length for derivative\n",
    "                 smooth_length=3 # smoothing window length after derivative\n",
    "                ):\n",
    "    \n",
    "    x, y = evenly_space(x, y) # to properly derive\n",
    "    \n",
    "    y_derive = np.zeros_like(y)\n",
    "    y_derive_smooth = np.zeros_like(y)\n",
    "    \n",
    "    x_min=min(x); x_max=max(x); lw=[4, 2, 0.5]; lines = ['k-','y-', 'r-']; label = ['Derivative', '2nd Smooth', '0 line']\n",
    "    \n",
    "    if deriv ==1:\n",
    "        y_label = r'${\\rm d/dE}$'\n",
    "    else :\n",
    "        y_label = r'$d^%s/dE^%s$' %(deriv,deriv)\n",
    "    \n",
    "    kwargs = {'x_min': x_min, 'x_max': x_max, 'y_label' : y_label  , 'title' : '', 'label': label, 'legend_title' : legend_title, 'legend_fs' : legend_fs, 'lines' : lines, 'lw' : lw, 'ms' : ms, \n",
    "              'figsize' : (12,4), \n",
    "         'is_x_numeric' : 1}\n",
    "    \n",
    "    for n in range(0, len(y[0,:])): # for all y columns of the data\n",
    "        # Smooth and take derivative for all columns except the X-axis column (0th Column)\n",
    "        y_derive[:,n] = scipy.signal.savgol_filter( [y[:,n]], derive_length, polyorder, deriv=deriv, axis=1)\n",
    "\n",
    "        # smooth the 2nd derivative again since it worked better in ignoring false peaks\n",
    "        y_derive_smooth[:,n]=scipy.signal.savgol_filter([y_derive[:,0],y_derive[:,n]], smooth_length, polyorder, deriv=0, axis=1)[1]\n",
    "        \n",
    "        kwargs['legend_title'] = data_labels[n]\n",
    "        \n",
    "        smart_plot( [x,x,[x_min,x_max]],[y_derive[:,n], y_derive_smooth[:,n], [0,0] ], **kwargs)\n",
    "\n",
    "    plt.show()\n",
    "    return  x, y_derive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Detect the zero crossings in a dataset\n",
    "# may correspond to peaks, dips etc. in the actual data\n",
    "\n",
    "def zero_cr(x, y, data_labels='', slope=0, zero=0, # see if crossing a non-zero value this way\n",
    "            x_min=0, x_max=4, # ignore outside these x values if there are no peaks for sure\n",
    "            is_plot=1, # whether to plot the 2nd derivatives and indicate the peak positions\n",
    "           ):\n",
    "    x_values=[] ; slope_values=[]; \n",
    "        \n",
    "    x_temp=x[:-1]# drop the last element of the x axis since np.diff(y) is 1 element shorter than x and y\n",
    "   \n",
    "    for n in range(0, len(y[0,:])): # for all y columns of the data\n",
    "       \n",
    "\n",
    "        diff_sign_y = np.diff(np.sign( y[:,n]-zero), axis=0)\n",
    "        diff_y = np.diff( y[:,n], axis=0)\n",
    "        \n",
    "        x_values_temp=[] ; slope_values_temp=[]\n",
    "        \n",
    "        for i in range(len(x_temp)):\n",
    "\n",
    "            if (x_temp[i] > x_min) & ( x_temp[i] < x_max) & (diff_sign_y[i] > 0) & (diff_y[i] > slope):\n",
    "\n",
    "                x_values_temp.append(x_temp[i])\n",
    "                slope_values_temp.append(diff_y[i])\n",
    "            \n",
    "        x_values.append(x_values_temp)\n",
    "        slope_values.append(slope_values_temp)\n",
    "            \n",
    "        # determine the A exciton x_value index (probably largest slope)\n",
    "        index_max = np.argmax(slope_values[n])\n",
    "\n",
    "        # determine the x_values[n] at a lower x_value than A exciton since we probably do not have any peaks there\n",
    "        del_indices=[]\n",
    "        for i in range(len(x_values[n])):\n",
    "            if x_values[n][i] < x_values[n][index_max]:\n",
    "                del_indices.append(i)\n",
    "        # delete the elements at those indices starting from the highest index to avoid confusion\n",
    "        for i in sorted(del_indices, reverse=True):\n",
    "            del x_values[n][i]\n",
    "            del slope_values[n][i]    \n",
    "        #sorted x_slope_values[n] (j[0] is used to convert array[1] to 1)\n",
    "        slope_values[n] = [ j for (k,j) in sorted((zip(x_values[n], slope_values[n])), key=lambda pair: pair[0])] # sort according to the peak positions\n",
    "        x_values[n].sort() # sort in ascending order\n",
    "\n",
    "\n",
    "        # plot (x,y) and mark the detected peak positions\n",
    "        smart_plot([x, x_values[n], [min(x),max(x)]], [y[:,n], [i*10**-2 for i in slope_values[n]], [0,0]], label=[data_labels[n],'Peaks','Zero Line'], lw=[1,.4,0.3], figsize=(16,4)\n",
    "                   ,lines=['-','x','-'], y_label='%s' %n, annotate = 1)\n",
    "    plt.show()\n",
    "        \n",
    "    report = pd.DataFrame(x_values, columns=[i for i in range(1, len(max(x_values, key=len))+1)], index=data_labels)\n",
    "    \n",
    "    return report, x_values,slope_values #,slope_values[n] # sort the x_values[n] in ascending order, convert to list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the index of a numpy array with the closest value\n",
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx, array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the local max of a numpy array\n",
    "def find_loc_max(x, y, x_lower, x_upper):\n",
    "    x, y= select_range(x, y ,x_lower, x_upper)\n",
    "    idx,max_y = find_nearest(y, max(y))\n",
    "    return x[idx], max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# round upto smallest integer multiple of base, such as 6,12,18 to 10,25,20 for base=5\n",
    "def round_upto_base(x, base=5):\n",
    "    return int(base * round(float(x)/base+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# round down to smallest integer multiple of base, such as 6,12,18 to 5,10,15 for base=5\n",
    "def round_to_base(x, base=5):\n",
    "    return int(base * round(float(x)/base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# round upto smallest (in log) power of base, such as 0.02 ,8, 89 to 0.01, 10, 100 if base=10 and return (20,-3), (8,1) (9,2)\n",
    "def round_upto_base_power(x1,x2,base=5):\n",
    "    x=x1-x2+10**-4 #add a small number in case x1=x2\n",
    "    N=int(np.log(x)/np.log(base)+0.5) # 0.5 makes sure to round up\n",
    "    return [int(x/base**(N-1)),N-1] # a format like [3,4] for x=350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    if x == 0:\n",
    "        return 0.5\n",
    "    return 0 if x < 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_lorentzian(x_upper,FWHM): # integration of a lorentzian broadened delta function\n",
    "    return integrate.quad(lambda x:lorentzian(x, FWHM), -inf, x_upper)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def voigt(x, FWHM_L,FWHM_G, center=0, Amplitude=1, constant=0):\n",
    "    return constant+Amplitude*integrate.quad(lambda xp:lorentzian(x-xp,FWHM_L,center)*gaussian(xp,FWHM_G,center), -inf, +inf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fwhm_voigt( FWHM_L,FWHM_G):\n",
    "    return  0.5346*FWHM_L + (0.2166*FWHM_L**2+FWHM_G**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fwhm_gauss_voigt(FWHM_V,FWHM_L):\n",
    "    return ((FWHM_V-0.5346*FWHM_L)**2-0.2166*FWHM_L**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fwhm_lorentz_voigt(FWHM_V,FWHM_G):\n",
    "    a=0.5346\n",
    "    b=0.2166\n",
    "    coefficients=[a**2-b,-2*a*FWHM_V, FWHM_V**2-FWHM_G**2]\n",
    "    FWHM_L= np.roots(coefficients)\n",
    "    FWHM_L=[i for i in FWHM_L if i < FWHM_V]\n",
    "    return FWHM_L[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thermal_voigt(x, FWHM_L,FWHM_G, kT=25, center=0, Amplitude=1, constant=0):\n",
    "    infinite= 10*kT\n",
    "    n=1\n",
    "    return constant+Amplitude*exp(-(x/kT)**n)*integrate.quad(lambda xp:lorentzian(x-xp,FWHM_L,center)*gaussian(xp,FWHM_G,center), -infinite, +infinite)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thermal_voigt2(x, FWHM_L,FWHM_G, kT=25, center=0, Amplitude=1, constant=0):\n",
    "    infinite= 10*kT\n",
    "    n=1\n",
    "    return constant+Amplitude*integrate.quad(lambda xp:exp(-(xp/kT)**n)*lorentzian(x-xp,FWHM_L,center)*gaussian(xp,FWHM_G,center), -infinite, +infinite)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thermal_lorentz(x, FWHM_L, kT=25, center=0, Amplitude=1, constant=0):\n",
    "    infinite= 10*kT\n",
    "    n=1\n",
    "    return constant+Amplitude*integrate.quad(lambda xp:exp(-(xp/kT)**n)*lorentzian(x-xp,FWHM_L,center), -infinite, +infinite)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert dielectric function to refractive index\n",
    "def epsilon_to_n(ϵ):\n",
    "    ϵ1 = ϵ.real; ϵ2 = ϵ.imag;\n",
    "    ϵ = np.sqrt(ϵ1**2+ϵ2**2)\n",
    "    n = np.sqrt((ϵ+ϵ1)/2) + 1j*np.sqrt((ϵ-ϵ1)/2) \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Refractive Index function out of the dielectric function parameters\n",
    "def refractive(x, sigma, center=1, amplitude=1, constant=1, fwhm=0):\n",
    "    fwhm = sigma*2\n",
    "    ϵ = epsilon2(x, sigma=sigma, center=center, amplitude=amplitude, constant=constant)\n",
    "    return epsilon_to_n(ϵ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imaginary part of this epsilon converges to the lorentzian lineshape when center>>FWHM\n",
    "def epsilon(x, FWHM, center=1, Amplitude=1, constant=1):\n",
    "    return constant+(center*Amplitude)*(2/pi)*(1/( x**2 - center**2 - 1j*x*FWHM))\n",
    "def epsilon2(x, sigma, center=1, amplitude=1, constant=1, fwhm=0):\n",
    "    FWHM = 2*sigma\n",
    "    return constant+(center*amplitude)*(2/pi)*(1/( x**2 - center**2 - 1j*x*FWHM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lorentzian(x, FWHM, center=0, Amplitude=1, constant=0):\n",
    "    return constant+Amplitude*(2/pi)*(FWHM/( (2*x - 2*center)**2 + FWHM**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d_lorentzian__d_FWHM(x, FWHM, center=0, Amplitude=1):\n",
    "    derivative = lambda FWHM: lorentzian(x, FWHM, center=0, Amplitude=Amplitude)\n",
    "    return scipy.misc.derivative(derivative,FWHM)\n",
    "\n",
    "def d_lorentzian__d_FWHM2(x, FWHM, center=0, Amplitude=1):\n",
    "    L = lorentzian(x, FWHM, center=center, Amplitude=Amplitude)\n",
    "    return L**2 * (pi/2) * ( (2*x/FWHM)**2 - 1) / Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(x, FWHM, center=0, Amplitude=1, constant=0):\n",
    "    sigma= FWHM/2.3548\n",
    "    return constant+Amplitude/(sigma*(2*pi)**0.5 )*exp(-0.5*(x/sigma)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_range(x, y, x_lower_limit, x_upper_limit, is_monotonic = 1):\n",
    "    \n",
    "    \n",
    "    if is_monotonic: # then just find the indices of x_lower_limit and x_upper_limit\n",
    "        lower_index, temp = find_nearest(x, x_lower_limit)\n",
    "        upper_index, temp = find_nearest(x, x_upper_limit)  \n",
    "        \n",
    "        if upper_index < lower_index:\n",
    "            temp = upper_index\n",
    "            upper_index = lower_index\n",
    "            lower_index = temp\n",
    "            \n",
    "        x = x[lower_index:upper_index]\n",
    "        y = y[lower_index:upper_index]\n",
    "        \n",
    "            \n",
    "    else: # not monotonic, check all the values one by one\n",
    "\n",
    "        x = x[(x_lower_limit < x) & (x < x_upper_limit)]\n",
    "        y = y[(x_lower_limit < x) & (x < x_upper_limit)]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FWHM2(X,Y):\n",
    "    half_max = max(Y) / 2.\n",
    "    #find when function crosses line half_max (when sign of diff flips)\n",
    "    #take the 'derivative' of signum(half_max - Y[])\n",
    "    d = np.sign(half_max - np.array(Y[0:-1])) - np.sign(half_max - np.array(Y[1:]))\n",
    "    #plot(X,d) #if you are interested\n",
    "    #find the left and right most indexes\n",
    "    left_idx = np.where(d > 0)[0]\n",
    "    right_idx = np.where(d < 0)[-1]\n",
    "    return (X[right_idx] - X[left_idx])[0] #return the difference (full width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the radius of curvature of a (x,y) plot at each x value\n",
    "def radius_curvature(x,y):\n",
    "    dx = np.gradient(x)\n",
    "    dy = np.gradient(y)/dx\n",
    "    ddy = np.gradient(dy)/dx\n",
    "    return dy , ((1 + dy**2)**1.5)/ddy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAY NOT BE IN USE (SEE MEMBRANE CALCULATIONS)\n",
    "def radius_curvature_2(x,y):\n",
    "    spl = scipy.interpolate.splrep(x,y,k=3) # no smoothing, 3rd order spline\n",
    "    ddy = scipy.interpolate.splev(x,spl,der=2) # use those knots to get second derivative \n",
    "    return ddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAY NOT BE IN USE (SEE MEMBRANE CALCULATIONS)\n",
    "#from scipy.interpolate import UnivariateSpline\n",
    "import numpy as np\n",
    "\n",
    "def curvature_splines(x, y=None, error=0.1):\n",
    "    \"\"\"Calculate the signed curvature of a 2D curve at each point\n",
    "    using interpolating splines.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x,y: numpy.array(dtype=float) shape (n_points, )\n",
    "         or\n",
    "         y=None and\n",
    "         x is a numpy.array(dtype=complex) shape (n_points, )\n",
    "         In the second case the curve is represented as a np.array\n",
    "         of complex numbers.\n",
    "    error : float\n",
    "        The admisible error when interpolating the splines\n",
    "    Returns\n",
    "    -------\n",
    "    curvature: numpy.array shape (n_points, )\n",
    "    Note: This is 2-3x slower (1.8 ms for 2000 points) than `curvature_gradient`\n",
    "    but more accurate, especially at the borders.\n",
    "    \"\"\"\n",
    "\n",
    "    # handle list of complex case\n",
    "    if y is None:\n",
    "        x, y = x.real, x.imag\n",
    "\n",
    "    t = np.arange(x.shape[0])\n",
    "    std = error * np.ones_like(x)\n",
    "\n",
    "    fx = UnivariateSpline(t, x, k=4, w=1 / np.sqrt(std))\n",
    "    fy = UnivariateSpline(t, y, k=4, w=1 / np.sqrt(std))\n",
    "\n",
    "    xˈ = fx.derivative(1)(t)\n",
    "    xˈˈ = fx.derivative(2)(t)\n",
    "    yˈ = fy.derivative(1)(t)\n",
    "    yˈˈ = fy.derivative(2)(t)\n",
    "    #curvature = (xˈ* yˈˈ - yˈ* xˈˈ) / np.power(xˈ** 2 + yˈ** 2, 3 / 2)\n",
    "    curvature = (1 + yˈ**2)**1.5/yˈˈ \n",
    "    return curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create file names for map measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_labels(L_x, L_y, L_z=0, dL_x=10, dL_y=10, dL_z=10):\n",
    "    labels=[]\n",
    "    coordinates = []\n",
    "    for j in range( int(L_y/dL_y) + 1):\n",
    "\n",
    "        for i in range( int(L_x/dL_x) + 1):\n",
    "\n",
    "            for k in range( int(L_z/dL_z) + 1):\n",
    "\n",
    "                coordinates.append([i*dL_x, j*dL_y, k*dL_z]) \n",
    "                labels.append('x_%.1f_y_%.1f_z_%.1f' %(i*dL_x, j*dL_y, k*dL_z))\n",
    "    return labels, coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_0.0_y_0.0_z_0.0', 'x_1.0_y_0.0_z_0.0', 'x_2.0_y_0.0_z_0.0', 'x_0.0_y_1.0_z_0.0', 'x_1.0_y_1.0_z_0.0', 'x_2.0_y_1.0_z_0.0', 'x_0.0_y_2.0_z_0.0', 'x_1.0_y_2.0_z_0.0', 'x_2.0_y_2.0_z_0.0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['x_0.0_y_0.0_z_0.0',\n",
       "  'x_1.0_y_0.0_z_0.0',\n",
       "  'x_2.0_y_0.0_z_0.0',\n",
       "  'x_0.0_y_1.0_z_0.0',\n",
       "  'x_1.0_y_1.0_z_0.0',\n",
       "  'x_2.0_y_1.0_z_0.0',\n",
       "  'x_0.0_y_2.0_z_0.0',\n",
       "  'x_1.0_y_2.0_z_0.0',\n",
       "  'x_2.0_y_2.0_z_0.0'],\n",
       " [[0, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [2, 0, 0],\n",
       "  [0, 1, 0],\n",
       "  [1, 1, 0],\n",
       "  [2, 1, 0],\n",
       "  [0, 2, 0],\n",
       "  [1, 2, 0],\n",
       "  [2, 2, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_labels(2,2, L_z=0, dL_x=1, dL_y=1, dL_z=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change names of multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0c78ab619b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Add WSe2_ to the names of the files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[1;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_address\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1L_A6_6_micron_#6a_0psi_PL\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Add WSe2_ to the names of the files\n",
    "\n",
    "with os.scandir(folder_address) as it:\n",
    "    for entry in it:\n",
    "        if entry.name.startswith(\"1L_A6_6_micron_#6a_0psi_PL\") and entry.is_file():\n",
    "            \n",
    "            os.renames( os.path.join(folder_address, entry.name) ,  os.path.join(folder_address, 'WSe2_'+ entry.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct the Labeling for OriginPro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_for_originpro(text_data, file=0, file_name='', folder_address='', output_folder_address='', print_OriginPro_commands=0):\n",
    "\n",
    "    if file: # if a file is being corrected for originpro\n",
    "        # Read the file\n",
    "        input_address= folder_address + file_name + '.txt'\n",
    "\n",
    "        with open(input_address, 'r') as file :\n",
    "            text_data = file.read()\n",
    "    \n",
    "    # Replace the target strings\n",
    "    # Put the commands in the priority order. I.e.; put 'A1s-A2s' before both 'A1s' and 'A2s'\n",
    "      \n",
    "    \n",
    "    command_names = ['_micron', '_${\\rm \\mu}m$','_${\\\\rm \\\\mu}$m', '${\\rm \\mu}m$','${\\\\rm \\\\mu}$m'] # as imported from originpro OR used in python\n",
    "    commands = [' \\g(m)m']*5 # proper command in originpro\n",
    "    originpro_names = [' μm']*5 # representation in originpro\n",
    "\n",
    "    \n",
    "    command_names.extend(['.asc'])\n",
    "    commands.extend([''])\n",
    "    originpro_names.extend([''])\n",
    "      \n",
    "    command_names.extend([' _PL', '_PL', ' _RC', '_RC'])\n",
    "    commands.extend(['', '', '', ''])\n",
    "    originpro_names.extend(['', '', '', ''])\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(commands)):\n",
    "        # replace 'micron' with '\\g(m)m'  (μm)\n",
    "        if isinstance(text_data, list):\n",
    "            text_data = [text.replace(command_names[i], commands[i]) for text in text_data]\n",
    "        else :\n",
    "            text_data = text_data.replace(command_names[i], commands[i]) \n",
    "\n",
    "    if file:# Write the file out again\n",
    "        output_address = output_folder_address + file_name + '_corrected.txt'\n",
    "        with open(output_address, 'w') as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    if print_OriginPro_commands:\n",
    "        for (command,originpro_name) in zip(commands,originpro_names):\n",
    "            if originpro_name:\n",
    "                print(r\" '%s' => '%s' in OriginPro\" %(command, originpro_name))\n",
    "\n",
    "    \n",
    "    \n",
    "    return text_data\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
